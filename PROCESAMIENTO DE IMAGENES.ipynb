{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155842ae-3f61-4690-9d12-50fd937cf81b",
   "metadata": {},
   "source": [
    "### PROCESAMIENTO DE IMAGENES: DATASET MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7479511a-103f-426b-a2e7-1a8f06e7b2f5",
   "metadata": {},
   "source": [
    "#### Guía paso a paso sin redes neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2951f1f9-7fb2-4150-b1b5-34ebf83dd329",
   "metadata": {},
   "source": [
    "#### 1. Descarga y Carga del Dataset\n",
    "##### Usaremos *\"sklearn\"* para cargar el dataset digits (similar a MNIST pero más simple)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd7d9c11-64f8-435b-b95b-ee332beaf46c",
   "metadata": {},
   "source": [
    "# %%\n",
    "from sklearn.datasets import load_digits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar dataset\n",
    "digits = load_digits()\n",
    "print(\"Dataset cargado exitosamente!\")\n",
    "     \n",
    "Dataset cargado exitosamente!\n",
    "\n",
    "# Ver estructura del dataset\n",
    "print(f\"\\nTipo de dato: {type(digits)}\")\n",
    "print(f\"Número de imágenes: {len(digits.images)}\")\n",
    "print(f\"Tamaño de cada imagen: {digits.images[0].shape}\")\n",
    "print(f\"Formato de las imágenes: {digits.images.shape}\")\n",
    "print(f\"Formato de las etiquetas: {digits.target.shape}\")\n",
    "     \n",
    "Tipo de dato: <class 'sklearn.utils._bunch.Bunch'>\n",
    "Número de imágenes: 1797\n",
    "Tamaño de cada imagen: (8, 8)\n",
    "Formato de las imágenes: (1797, 8, 8)\n",
    "Formato de las etiquetas: (1797,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efce013d-ea89-4e08-a295-32657c9c4a44",
   "metadata": {},
   "source": [
    "#### Este código carga el dataset digits de scikit-learn, que contiene 1,797 imágenes de dígitos manuscritos (0-9). Cada imagen es una matriz de 8x8 píxeles (64 características en escala de grises). Las imágenes están almacenadas en un arreglo 3D (1797, 8, 8) y las etiquetas en un vector 1D (1797,). Este conjunto es ideal para practicar clasificación de imágenes, reducción de dimensionalidad y técnicas de machine learning básicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b1e5f3-1a8d-4a80-9c6b-f27e6095b77f",
   "metadata": {},
   "source": [
    "#### 2. Inspección de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785b8e73-2857-4d10-b688-93f3dc201f22",
   "metadata": {},
   "source": [
    "##### Mostrar algunos ejemplos de datos crudos"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59096033-7271-4b50-90ae-f7b21a83ffda",
   "metadata": {},
   "source": [
    "print(\"Primeras 3 imágenes (formato plano):\")\n",
    "print(digits.images[:3].reshape(3, -1))\n",
    "\n",
    "print(\"\\nEtiquetas correspondientes:\")\n",
    "print(digits.target[:3])\n",
    "\n",
    "     \n",
    "Primeras 3 imágenes (formato plano):\n",
    "[[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
    "  15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
    "   0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
    "   0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n",
    " [ 0.  0.  0. 12. 13.  5.  0.  0.  0.  0.  0. 11. 16.  9.  0.  0.  0.  0.\n",
    "   3. 15. 16.  6.  0.  0.  0.  7. 15. 16. 16.  2.  0.  0.  0.  0.  1. 16.\n",
    "  16.  3.  0.  0.  0.  0.  1. 16. 16.  6.  0.  0.  0.  0.  1. 16. 16.  6.\n",
    "   0.  0.  0.  0.  0. 11. 16. 10.  0.  0.]\n",
    " [ 0.  0.  0.  4. 15. 12.  0.  0.  0.  0.  3. 16. 15. 14.  0.  0.  0.  0.\n",
    "   8. 13.  8. 16.  0.  0.  0.  0.  1.  6. 15. 11.  0.  0.  0.  1.  8. 13.\n",
    "  15.  1.  0.  0.  0.  9. 16. 16.  5.  0.  0.  0.  0.  3. 13. 16. 16. 11.\n",
    "   5.  0.  0.  0.  0.  3. 11. 16.  9.  0.]]\n",
    "\n",
    "Etiquetas correspondientes:\n",
    "[0 1 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460d7d12-2cdd-4678-acd0-b6c693ef3a6e",
   "metadata": {},
   "source": [
    "#### El código muestra las primeras 3 imágenes en formato plano (vector de 64 valores) y sus etiquetas correspondientes [0, 1, 2].\n",
    "\n",
    "Análisis:\n",
    "\n",
    "-Cada imagen está representada como un vector de 64 valores numéricos (8x8 píxeles aplanados)\n",
    "\n",
    "-Los valores van de 0 a 15, representando intensidades de gris\n",
    "\n",
    "-La primera imagen (etiqueta 0) muestra patrones típicos de un cero manuscrito\n",
    "\n",
    "-La segunda (etiqueta 1) y tercera (etiqueta 2) muestran patrones característicos de unos y doses\n",
    "\n",
    "#### Este formato plano es el que normalmente se usa como input para algoritmos de machine learning, mientras que la versión matricial (8x8) es útil para visualización."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81cbbae-e067-41f5-92b3-fa5af60fbdee",
   "metadata": {},
   "source": [
    "#### 3. Visualización de imágenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa08ea7c-1b37-45f9-ba87-32652efb67ae",
   "metadata": {},
   "source": [
    "##### Función para mostrar múltiples imágenes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b0e0a7e-0170-4e01-ae5f-ce8a0d3636e0",
   "metadata": {},
   "source": [
    "def plot_digits(images, labels, n_rows=4, n_cols=5):\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, 8))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(images):\n",
    "            ax.imshow(images[i], cmap='gray')\n",
    "            ax.set_title(f\"Label: {labels[i]}\")\n",
    "            ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Mostrar primeras 20 imágenes\n",
    "plot_digits(digits.images, digits.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6885a3c3-e3a0-4894-ad72-f9952385b841",
   "metadata": {},
   "source": [
    "#### La función plot_digits crea una cuadrícula de 4 filas × 5 columnas (20 imágenes totales) mostrando:\n",
    "\n",
    "-Cada dígito en escala de grises.\n",
    "\n",
    "-Su etiqueta correspondiente arriba de cada imagen\n",
    "\n",
    "-Sin ejes para mejor visualización\n",
    "\n",
    "#### Propósito: Esta visualización ayuda a:\n",
    "\n",
    "-Ver la diversidad de estilos de escritura manual\n",
    "\n",
    "-Identificar patrones característicos de cada dígito\n",
    "\n",
    "-Detectar posibles desafíos de clasificación (dígitos ambiguos o mal escritos)\n",
    "\n",
    "-Validar la correspondencia entre imágenes y etiquetas\n",
    "\n",
    "#### Es un paso esencial antes de entrenar modelos para entender la naturaleza del dataset.\n",
    "\n",
    "\n",
    "#### Este código dibuja las primeras 20 imágenes del dataset en una cuadrícula, mostrando visualmente cada dígito y su etiqueta, facilitando la comprensión de cómo se ven los datos originales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d922d3-bcc0-4353-81cc-7b359de3573a",
   "metadata": {},
   "source": [
    "#### 4. Análisis Estadístico Básico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108750a4-9175-4ee8-a9e5-f29be2a49801",
   "metadata": {},
   "source": [
    "##### Veamos propiedades interesantes de las imágenes:\n",
    "##### Calcular el promedio de pixeles por dígito\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca739a74-980b-4295-b741-33538f9be2e1",
   "metadata": {},
   "source": [
    "digit_means = {}\n",
    "for digit in range(10):\n",
    "    digit_imgs = digits.images[digits.target == digit]\n",
    "    digit_means[digit] = np.mean(digit_imgs, axis=0)\n",
    "\n",
    "# Mostrar promedios\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "for digit, ax in zip(range(10), axes.flat):\n",
    "    ax.imshow(digit_means[digit], cmap='gray')\n",
    "    ax.set_title(f\"Dígito {digit}\")\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Promedio de píxeles por dígito\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f79a340-e403-4221-8b62-65f200a3b763",
   "metadata": {},
   "source": [
    "#### Este código calcula y visualiza el promedio de intensidad de píxeles para cada dígito (0-9). Para cada número, se promedian todas sus imágenes en el dataset, creando una imagen compuesta que muestra los patrones característicos.\n",
    "\n",
    "#### Resultado: Se observa que cada dígito mantiene su forma esencial en el promedio, pero con bordes suavizados. Esto revela:\n",
    "\n",
    "-Los patrones comunes de escritura para cada número\n",
    "\n",
    "-Las zonas con mayor intensidad (trazos más consistentes)\n",
    "\n",
    "-La variabilidad natural en la escritura manual\n",
    "\n",
    "#### Estos promedios sirven como \"huellas digitales\" de cada número y pueden usarse como referencia para tasks de reconocimiento básico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0fe95a-549b-4e3e-afa2-88e3f2d75dff",
   "metadata": {},
   "source": [
    "#### 5. Preprocesamiento Básico"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae914d8-4674-4256-8f39-a70c401562b3",
   "metadata": {},
   "source": [
    "##### Vamos a realizar algunas operaciones comunes sin redes neuronales"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8f25d23-185c-478c-b349-81d73a5e3fe4",
   "metadata": {},
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Ejemplo: Umbralización (binarización)\n",
    "def binarize_image(img, threshold=None):\n",
    "    \"\"\"Convierte imagen a blanco y negro\"\"\"\n",
    "    if threshold is None:\n",
    "        threshold = threshold_otsu(img)\n",
    "    return img > threshold\n",
    "\n",
    "# Aplicar a una imagen de muestra\n",
    "sample_img = digits.images[0]\n",
    "binary_img = binarize_image(sample_img)\n",
    "\n",
    "# Mostrar resultado\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax1.imshow(sample_img, cmap='gray')\n",
    "ax1.set_title(\"Original\")\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(binary_img, cmap='gray')\n",
    "ax2.set_title(\"Binarizada\")\n",
    "ax2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad15a00c-8431-419c-887f-2ec0ff74a4a3",
   "metadata": {},
   "source": [
    "#### Convierte una imagen de números escrita a mano (en tonos de gris) en una imagen solo de blanco y negro puros, sin grises.\n",
    "\n",
    "-Original: La imagen tiene muchos tonos de gris (claros, oscuros, medios)\n",
    "\n",
    "-Binarizada: Usa un truco inteligente para encontrar el punto perfecto que separa lo que debería ser negro (el fondo) de lo que debería ser blanco (el número).\n",
    "\n",
    "#### Es como pasar de un lápiz (que hace grises) a un rotulador (que hace negro o blanco puro). Así la computadora puede ver el número más claramente, sin distraerse con los tonos de gris.\n",
    "\n",
    "#### Resultado: La imagen queda mucho más definida, lo que facilita que los algoritmos identifiquen la forma del número correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dbd14d-2260-4b95-859e-e3d6cf485b9d",
   "metadata": {},
   "source": [
    "#### 6. Extracción de Características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01915a4f-34ff-4574-ab81-32334741ca9e",
   "metadata": {},
   "source": [
    "##### Sin redes neuronales, podemos extraer características manuales"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6ad289f-d1a0-4259-a880-7d9586903dab",
   "metadata": {},
   "source": [
    "# %%\n",
    "from skimage.feature import hog\n",
    "from skimage.measure import moments, moments_hu\n",
    "\n",
    "# Extraer HOG features (Histogram of Oriented Gradients)\n",
    "def extract_hog_features(image):\n",
    "    fd, hog_image = hog(\n",
    "        image,\n",
    "        orientations=8,\n",
    "        pixels_per_cell=(2, 2),\n",
    "        cells_per_block=(1, 1),\n",
    "        visualize=True,\n",
    "        block_norm='L2-Hys'\n",
    "    )\n",
    "    return fd, hog_image\n",
    "\n",
    "# Aplicar a una imagen\n",
    "hog_feat, hog_img = extract_hog_features(sample_img)\n",
    "\n",
    "# Mostrar HOG\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax1.imshow(sample_img, cmap='gray')\n",
    "ax1.set_title(\"Imagen Original\")\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(hog_img, cmap='gray')\n",
    "ax2.set_title(\"HOG Features\")\n",
    "ax2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a617f16-eca7-4bd7-97fa-71a7e0830443",
   "metadata": {},
   "source": [
    "#### Es una técnica de extracción de características que analiza la dirección y intensidad de los bordes de una imagen. En lugar de usar los píxeles directamente, describe cómo se organizan los patrones visuales.\n",
    "\n",
    "-Divide la imagen en celdas pequeñas (ej: 2x2 píxeles).\n",
    "\n",
    "-En cada celda, calcula la dirección predominante de los bordes (gradientes).\n",
    "\n",
    "-Crea un histograma que resume estas direcciones en toda la imagen.\n",
    "\n",
    "-Genera una representación compacta y numérica de la forma del objeto.\n",
    "\n",
    "#### Sirve para el reconocimiento de patrones: Identificar objetos (dígitos, rostros, etc.) aunque varíen en tamaño o estilo. Reducción de complejidad, convertir una imagen de 64 píxeles en un vector de características más manejable, funciona bien incluso con cambios de iluminación o pequeñas deformaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ec724-65e1-4e04-be4e-771ae4db8f83",
   "metadata": {},
   "source": [
    "#### 7. Transformaciones Geométricas"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6759b13e-c7ca-4332-ac84-07939a986afb",
   "metadata": {},
   "source": [
    "from skimage.transform import rotate, rescale\n",
    "\n",
    "# Rotar imagen\n",
    "rotated = rotate(sample_img, angle=15)\n",
    "\n",
    "# Escalar imagen\n",
    "scaled = rescale(sample_img, scale=1.5)\n",
    "\n",
    "# Mostrar resultados\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "axes[0].imshow(sample_img, cmap='gray')\n",
    "axes[0].set_title(\"Original\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(rotated, cmap='gray')\n",
    "axes[1].set_title(\"Rotada 15°\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "axes[2].imshow(scaled, cmap='gray')\n",
    "axes[2].set_title(\"Escalada 1.5x\")\n",
    "axes[2].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b889e0-bfb6-4e83-afe7-00bba98ff846",
   "metadata": {},
   "source": [
    "#### Este código modifica la imagen original del número aplicando dos cambios geométricos:\n",
    "-Rotación: Inclina la imagen 15 grados\n",
    "-Escalado: Agranda la imagen 1.5 veces su tamaño original\n",
    "\n",
    "#### Usa:\n",
    "-Rotar: Usa rotate() para girar la imagen manteniendo su contenido\n",
    "\n",
    "-Escalar: Usa rescale() para ampliar la imagen sin distorsionar su forma\n",
    "#### El código transforma imágenes de dígitos: rota 15° para simular inclinación y escala 1.5× para cambiar tamaño. Estas transformaciones ayudan a generar más datos para entrenamiento y mejorar robustez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45df8e0d-db0b-420c-b120-2e920047b2e7",
   "metadata": {},
   "source": [
    "#### 8. Detección de Bordes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad3cc37a-1f3c-4790-8ac9-c335b642b2e7",
   "metadata": {},
   "source": [
    "# %%\n",
    "from skimage.filters import sobel\n",
    "\n",
    "# Detectar bordes con Sobel\n",
    "edges = sobel(sample_img)\n",
    "\n",
    "# Mostrar resultado\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax1.imshow(sample_img, cmap='gray')\n",
    "ax1.set_title(\"Original\")\n",
    "ax1.axis('off')\n",
    "\n",
    "ax2.imshow(edges, cmap='gray')\n",
    "ax2.set_title(\"Bordes detectados\")\n",
    "ax2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df08718-3d29-4ac6-8efc-2a63a755f823",
   "metadata": {},
   "source": [
    "#### Este código encuentra los bordes (las líneas que separan las zonas claras y oscuras) del número en la imagen.\n",
    "\n",
    "#### ¿Cómo lo hace?\n",
    "-Usa un filtro especial llamado Sobel que:\n",
    "\n",
    "-Escanea la imagen buscando cambios bruscos de color (de blanco a negro o viceversa)\n",
    "\n",
    "-Destaca estas zonas de transición donde hay bordes\n",
    "\n",
    "-Suaviza el resto de la imagen donde no hay cambios abruptos\n",
    "\n",
    "#### Se obtiene una versión donde solo se ven los bordes del número, como si fuera un dibujo lineal. Como pasar de una foto a un dibujo de contorno. Es como cuando delineamos un dibujo con marcador negro para que se vea más definido, antes de colorearlo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2e8e7c-cfb3-4128-a28a-d58852afc61f",
   "metadata": {},
   "source": [
    "#### 9. Ejercicios Prácticos"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b54eb83-98d1-459a-94dd-132c971a3856",
   "metadata": {},
   "source": [
    "# ### Ejercicio 1:\n",
    "# Crea una función que calcule el número de píxeles blancos (valor alto) en cada imagen y compara con la etiqueta real\n",
    "\n",
    "# %%\n",
    "def count_white_pixels(img):\n",
    "    \"\"\"Cuenta píxeles con valor alto (casi blanco)\"\"\"\n",
    "    return np.sum(img > 15)  # Umbral arbitrario\n",
    "\n",
    "# Probar con algunas imágenes\n",
    "for i in range(5):\n",
    "    white_count = count_white_pixels(digits.images[i])\n",
    "    print(f\"Imagen {i}: {white_count} píxeles blancos, etiqueta: {digits.target[i]}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3eb916ed-e502-4185-9e89-b15e879a0f0e",
   "metadata": {},
   "source": [
    "Imagen 0: 0 píxeles blancos, etiqueta: 0\n",
    "Imagen 1: 11 píxeles blancos, etiqueta: 1\n",
    "Imagen 2: 7 píxeles blancos, etiqueta: 2\n",
    "Imagen 3: 0 píxeles blancos, etiqueta: 3\n",
    "Imagen 4: 5 píxeles blancos, etiqueta: 4"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61fa6842-5015-4977-b7d0-57d0a26cd3a8",
   "metadata": {},
   "source": [
    "# ### Ejercicio 3:\n",
    "# Calcula y visualiza el histograma de intensidades para cada dígito\n",
    "\n",
    "# %%\n",
    "# Crear figura con subplots\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for digit in range(10):\n",
    "    digit_imgs = digits.images[digits.target == digit]\n",
    "    # Promediar histogramas de todas las imágenes del dígito\n",
    "    hist_sum = np.zeros(16)\n",
    "    for img in digit_imgs:\n",
    "        hist, _ = np.histogram(img.ravel(), bins=16, range=(0, 16))\n",
    "        hist_sum += hist\n",
    "\n",
    "    axes[digit].bar(range(16), hist_sum / len(digit_imgs))\n",
    "    axes[digit].set_title(f\"Dígito {digit}\")\n",
    "    axes[digit].set_ylim(0, 50)\n",
    "\n",
    "plt.suptitle(\"Histograma de Intensidades por Dígito\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adb0487-f739-44fb-9fe0-cbd63afbaec8",
   "metadata": {},
   "source": [
    "##### Se calcula el histograma de intensidades para cada dígito, promediando todas sus imágenes. Permite visualizar la distribución de brillo y contraste típico de cada número, útil en análisis y clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd103718-171a-4ddb-8c24-cbdbf4d9b10c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
